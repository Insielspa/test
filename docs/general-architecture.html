<!DOCTYPE html SYSTEM "about:legacy-compat">
<html lang="en-US" data-preset="contrast" data-primary-color="#307FFF"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="UTF-8"><meta name="robots" content="noindex"><meta name="built-on" content="2024-09-25T18:21:47.374328884"><title>Application Architecture | FVG Vision AI</title><script type="application/json" id="virtual-toc-data">[]</script><script type="application/json" id="topic-shortcuts"></script><link href="https://resources.jetbrains.com/writerside/apidoc/6.10.0-b419/app.css" rel="stylesheet"><meta name="msapplication-TileColor" content="#000000"><link rel="apple-touch-icon" sizes="180x180" href="https://jetbrains.com/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="https://jetbrains.com/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="https://jetbrains.com/favicon-16x16.png"><meta name="msapplication-TileImage" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-144x144.png"><meta name="msapplication-square70x70logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-70x70.png"><meta name="msapplication-square150x150logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-150x150.png"><meta name="msapplication-wide310x150logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-310x150.png"><meta name="msapplication-square310x310logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-310x310.png"><meta name="image" content=""><!-- Open Graph --><meta property="og:title" content="Application Architecture | FVG Vision AI"><meta property="og:description" content=""><meta property="og:image" content=""><meta property="og:site_name" content="FVG Vision AI Help"><meta property="og:type" content="website"><meta property="og:locale" content="en_US"><meta property="og:url" content="writerside-documentation/general-architecture.html"><!-- End Open Graph --><!-- Twitter Card --><meta name="twitter:card" content="summary_large_image"><meta name="twitter:site" content=""><meta name="twitter:title" content="Application Architecture | FVG Vision AI"><meta name="twitter:description" content=""><meta name="twitter:creator" content=""><meta name="twitter:image:src" content=""><!-- End Twitter Card --><!-- Schema.org WebPage --><script type="application/ld+json">{
    "@context": "http://schema.org",
    "@type": "WebPage",
    "@id": "writerside-documentation/general-architecture.html#webpage",
    "url": "writerside-documentation/general-architecture.html",
    "name": "Application Architecture | FVG Vision AI",
    "description": "",
    "image": "",
    "inLanguage":"en-US"
}</script><!-- End Schema.org --><!-- Schema.org WebSite --><script type="application/ld+json">{
    "@type": "WebSite",
    "@id": "writerside-documentation/#website",
    "url": "writerside-documentation/",
    "name": "FVG Vision AI Help"
}</script><!-- End Schema.org --></head><body data-id="General-architecture" data-main-title="Application Architecture" data-article-props="{&quot;seeAlsoStyle&quot;:&quot;links&quot;}" data-template="article" data-breadcrumbs="starter.md|FVG Vision AI"><div class="wrapper"><main class="panel _main"><header class="panel__header"><div class="container"><h3>FVG Vision AI  Help</h3><div class="panel-trigger"></div></div></header><section class="panel__content"><div class="container"><article class="article" data-shortcut-switcher="inactive"><h1 data-toc="General-architecture" id="General-architecture.md">Application Architecture</h1><p id="z8eyq36_3">FVG Vision AI is structured into a modular architecture designed to facilitate flexibility, scalability, and ease of configuration. Each module handles a specific task within the application, allowing for clear separation of concerns and easy customization.</p><p id="z8eyq36_4">The main components of the architecture are as follows:</p><ol class="list _decimal" id="z8eyq36_5" type="1"><li class="list__item" id="z8eyq36_8"><p id="z8eyq36_14"><span class="control" id="z8eyq36_15">Input Module</span><br> The Input module is responsible for capturing video streams. The system supports video input from both local sources (e.g., video files) and network streams via RTSP. The video feed is handled using OpenCV.</p></li><li class="list__item" id="z8eyq36_9"><p id="z8eyq36_17"><span class="control" id="z8eyq36_18">Processing Module</span><br> The Processing module is the core of the application. It performs object detection and scenario-specific analytics using the Ultralytics library. The module can process various real-time analytics scenarios, such as people counting, parking space monitoring, and hand-raise detection.</p></li><li class="list__item" id="z8eyq36_10"><p id="z8eyq36_20"><span class="control" id="z8eyq36_21">Notification Module</span><br> The Notification module connects to external services, such as Azure IoT Hub, to send real-time alerts based on events detected during video analysis. Notifications are triggered by configurable thresholds or conditions.</p></li><li class="list__item" id="z8eyq36_11"><p id="z8eyq36_23"><span class="control" id="z8eyq36_25">Output Module</span><br> The Output module is responsible for delivering the processed video stream or snapshots. It supports two main output formats:</p><ul class="list _bullet" id="z8eyq36_24"><li class="list__item" id="z8eyq36_27"><p><span class="control" id="z8eyq36_29">HLS (HTTP Live Streaming)</span> for continuous video streaming.</p></li><li class="list__item" id="z8eyq36_28"><p><span class="control" id="z8eyq36_30">JPEG</span> snapshots delivered via HTTP. </p><br><p> The output is served using an Nginx server integrated within the Docker container.</p></li></ul></li><li class="list__item" id="z8eyq36_12"><p id="z8eyq36_32"><span class="control" id="z8eyq36_33">Configuration and Control</span><br> The application allows configuration through multiple methods, including default configuration files, environment variables, and command-line arguments. The configuration can be customized for both input sources and processing scenarios.</p></li><li class="list__item" id="z8eyq36_13"><p id="z8eyq36_35"><span class="control" id="z8eyq36_36">Benchmarking Module</span><br> The Benchmarking module is a specialized component used to evaluate the system's performance. It provides metrics such as FPS (frames per second) and resource usage, which are useful for optimizing the application for different hardware environments.</p></li></ol><p id="z8eyq36_6">Below is a visual representation of FVG Vision AI's architecture:</p><div class="last-modified">Last modified: 25 September 2024</div><div data-feedback-placeholder="true"></div><div class="navigation-links _bottom"><a href="goals-and-use-cases.html" class="navigation-links__prev">Main goals</a><a href="requirements.html" class="navigation-links__next">System Requirements</a></div></article><div id="disqus_thread"></div></div></section></main></div><script src="https://resources.jetbrains.com/writerside/apidoc/6.10.0-b419/app.js"></script></body></html>